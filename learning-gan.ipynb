{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Learning `Deep Convolutional GAN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119ffae80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztfVuIbNl53re6uqqrq/pyzmROhkHWZJwgAsYQORz0YhEU\nHBtZBMZ+EdaDMybCxw8RxKAHC+UhInkZgi8YEgzjaPAoOHICttAQROKJSBCGYHQkFF0sJ1LEGM8w\nmjmjOae7q6sv1d0rD13fPl/9vdau3V3X7v1/sNm7du2qWrXZ3/rv/woxRjgcjvphZdEDcDgci4GT\n3+GoKZz8DkdN4eR3OGoKJ7/DUVM4+R2OmsLJ73DUFE5+h6OmcPI7HDXF6jx/7Mknn4zPPvvsPH/S\n4agVXnvtNbzzzjuhyrUTkT+E8GEAvwugAeDfxxhfKLv+2Wefxf379yf5SYfDUYK7d+9WvvbKan8I\noQHg3wH4eQA/AeBjIYSfuOr3ORyO+WISm/8DAL4fY/xBjPEYwB8BeG46w3I4HLPGJOR/D4C/ltev\nD8+NIIRwL4RwP4Rw/8GDBxP8nMPhmCZm7u2PMb4YY7wbY7x7586dWf+cw+GoiEnI/waA98rrHxue\nczgc1wCTkP+rAN4XQvjxEEILwC8BeGU6w3I4HLPGlUN9McaTEMInAPw3nIf6XooxfmdqI3M4HDPF\nRHH+GOOXAHxpSmNxOBxzhKf3Ohw1hZPf4agpnPwOR03h5Hc4aoq5VvU56otJ1ocIoVKRmuOScPI7\nZoIc2S8zCZD09jM+GUwHTn7HVKFEtaQte88ihIAY4wjRU5OBTwRXh5PfMRWkiF11b0FChxBGjlPX\n2AnCUR1OfsfEsMRXctstdY3CEj63Ken5HT4JXA5OfsdESBFft7Ozs9LXKRU+hICVlZViz2O72c+5\nFnA5OPkdU0GK4Lrndnp6itPT0+K1TgAkdaPRGNk4AeiEQKS0AJ8AqsHJ77gyUuq9kpokPzk5wenp\nKU5OTopjnQQUJPzq6ipWV1fRbDaxuro6MhEAGJkEUs5Bx3g4+R1XQhnxVcIPBgOcnJxgMBhc2E5O\nTorrAWBlZaUg/draGlqtFk5PT9FsNtFqtUZ+f2VlJev194mgGpz8jspIhe7KiH98fDyyHR4e4ujo\nCMfHxxgMBsWe5G80GlhbWyu2druN9fX1C9oBcE72s7OzEROA5x3V4OR3jEUuXp8j/snJSUH4o6Mj\nHB4e4uDgAIeHhzg8PMT+/j4ODg5wdHSEwWCA09NTACgkfrfbxebmJk5OTpJOQW6U/k74q8HJ7yjF\nuPh9mcQn6Q8ODtDv97G3t4der1eQ//DwcETyN5tNrK2t4fDwEMfHx8WkAKBw+DUajQshP3UY+mRQ\nHU5+RxLjpL2V+iQ+1frDw0P0+330+33s7+9jZ2cHOzs7WfKHENBsNrG+vo7j42OcnJwAQOH8azab\nIxEAqvwch3v9Lw8nv+MCctKexzaEpxL/6OgIR0dH2N/fL4j/6NEjPHr0CLu7u9jb2xshP51+Kysr\naDabODo6wunpKUIIWF1dRbvdRqvVQqvVQrPZLH6LE4BKfyf75eDkd4ygjPg2jq8hOyU+Sb+3t4ed\nnR08fPiwIH6v10Ov1yucf4PBADFGNBqNgtwkfqvVQrfbxfr6OtrtNtbW1kZChNbj7xPA5eDkdxQY\nR3yV+CShOvdo45P4KvGV/P1+v/AFDAYDAOc2fafTKYi/traGTqcz4hhkjoDmEugYnfiXg5PfAaA6\n8Uk+SvvBYDAi8enYU+Lv7OyMOPs4ARweHo54+mOMBfEZCuRvqMTn3kYCOGafBKrBye+oRPyyGD6d\newcHB9jZ2cHu7m5B/r29vRHi7+7uFv6A4+Pjwm5fW1tDo9EoJLxmAupxqjbAJ4Crwclfc5QRP+XY\no5o/GAyKuD2JT9LTs7+7u1vY+CT+3t5eIfXp0WfOfqvVuqDa6zaO8I7LwclfY1yV+HTu0W4nsVXN\nV+L3er2R1yT+6elpEbtXkus4UmOzY3dcDU7+msIS3ybulEl8S3ySXsN5VO9JfEr8g4ODQq3n766s\nrIzk99uyXVfhZwMnfw2RI36qFDel6pP4vV4POzs7haqfIj5t/v39/SJzj8QHHhObGoBm8tlznBj0\nc46rw8lfM1Qlvpbj5lR9S3wN59EU4DHj+nTcMbZPCZ8q4bV7nQTsROCTweXh5K8RUjY+j8uSd1LE\npze/jPjq3GOuPp18tnEHk3parVYxCTCrT1N7q2gAPhFUg5O/Jhjn3LPEZw3+ZYmveyU+HXwEVXrG\n9dvtdpHKy5LeZrNZnKNmYCcAOwk48atjIvKHEF4DsAfgFMBJjPHuNAblmB0uQ3wW6Vivvm42jp8i\nvqr6LMWldF9bW8P6+jrW19fR6XQu1PPrRJBS/90xeHVMQ/L/wxjjO1P4HseMkAuZaexcs+fKiG+L\ndOjMK1P1tVkHVf1Wq1U062D9Pl93Op1iT8mfaueVa+jpqAZX+2uGXBxfnXtXIb7m7Wu1HiccEpbq\ne7vdRqfTKYjf6XSKrdvtFlun0xnxBZD84wjvk8F4TLpQZwTwpyGEr4UQ7k1jQI7pIleZV5bAkyN+\nSs23Ev/o6KiI42vsntK+1WqNSPutrS1sbm5iY2Oj2Phet9stVH9K/tXV1aTa7xrA5TGp5P9gjPGN\nEMLfBPBqCOEvY4xf0QuGk8I9AHjmmWcm/DnHpCiL4182c8/m6rM5B+P4GsYj+Wnfk+TcNjc3i8mA\nE0IZ+T3MNzkmkvwxxjeG+7cBfAHABxLXvBhjvBtjvHvnzp1Jfs5xSVSR+lWIr559m7JL4lPiW8ce\nQ3Xr6+sFuW/duoVbt25he3t7ZLt16xZu376NW7duYWtrq6jj15BfKtbvE8DVcGXJH0LoAliJMe4N\nj38OwL+a2sgcEyFV+KLE19baVVN2U8RnVx4r8dW+p/Ou0+kUEl+PKem3traKiYDXa6gvFeZLrdzj\nE0E1TKL2PwXgC8MbvQrgP8YY/+tURuWYCKkEnlRprsbxtRFHrgkHHXyW+JqrDzzuv0+Pvjr2qObT\nvrfq/tbW1gjx2b+fiT5u508PVyZ/jPEHAP7eFMfimAJyxLdSX5tlsCxX4/hswKF99zSJJ1WkA4wS\nnyE7Epyktzb+9vZ24fTjZ0h6S/yc5PcJ4PLwUN8NQlWJr7F87cBjm3BY4quNb1V94CLxKeW3trZG\nJD8lPFV8ntdefTa1N5fYAyB77CiHk/+GoCrxbUiPRGazTavuW+JrPf444qvEp2Tf3t4eIT4de2rf\n26QeXaDTrtHnxL86nPw3DJeR+LqYhpbkagLPZYnPLD1LfLXp6e1X55+m8dpCHl2hJ6fqO/EvDyf/\nDUAqpJciPjP3SHwSmm23Uo02c8Rn7z1ts91ut9Htdkds+Bzxraqfy+LLpfE68SeHk/+a47LEV+de\nrhmH9e6XEZ+ltyQ+Jb4S38byNZ2XEr8K8YGLRHfiXx1O/huEVNpubgkt215b4/iaq58iPoAs8be3\ntwvi06antKeqX0b8XNouf5Nw0k8OJ/81Rk7qa3luKpxXtqCGNtssy9XPEd/a+Jq1p6G8lKpfpVTX\nST89OPmvIXJdeHJr59lFM23Kbqr1lg3njVP1NZxHVZ/Ev3379oUYPiW+7dAzLnvPMT04+a8ZUrX5\nWpefyt6jV7/X6+Hdd98d6cCjIb2yOP444lvn3vb29ojEp3PPNueokqvvxJ8NnPzXCGXEt3F8G86j\nxFcHn4b0+DqVqw/kbXwr8auq+jaU58SfP5z81wS5Cj218dl+i1LfEj/l1S9T9XNx/DIbX7366tyz\npbllNfmEE3+2cPJfA4xrw0XiU+qzSKcK8W1f/XEJPCnib2xsXIjjU83XPH3N2iuL4QNO/HnAyX/N\nkHLwaaddrp/Hqrtcp10l/sHBQXJBjVSRjubi21Jcqvsax9dcfRvDz7XgduLPB07+JUdZ080y4vf7\n/dJFNXRlHevVB0bDedp2K5e5RxufxGcXHq3KSxHfSb84OPmvAXJluSkHH1X9HPEp8Xd3dwsbn0tx\npbz644jPjjxPPPHESNNNSnsuve0tt5cPTv4lRq4bT64FlzbUzCXxaLPNfr9ftNdOefVto00bx7fh\nPNt9R4lfNV3XMT84+ZcUVXL2Vd23Nfk5VZ/SX4nPlXQmIX6qHj+1xJar+csDJ/+Soawuf1wnHkp2\nVujZmnxm8eWIz1V0qhL/9u3bF1T9y2buORYHJ/+SoiyFVxtvau89bcZhF9Sg9LdLaAGPiW8bcZD4\nqZLcVMpuu91OhvNc3V9OOPmXCJdJ3VWVn514bGUeE3e0r74ukw2MEj/XiMOG82wc3ybwVMnccywe\nTv4lQZVW27nQnjrylPgHBwcjqj6Jr2W5qQSeVD1+rixXbfwqZbn8Xcfi4eRfMpQtsGGXzlZbX+16\nJT6PB4PByGq5JGnV6ryUqm9z9T1l93rByb8EKEvfzWXysVRX1Xztpa+NOI6OjjAYDEZWy1XicwGN\nVJGOZu5Z4qece5b0TvzlhZN/yZCbAFLEp9RX1Z45/UzZVeKfnZ0Vkplx+E6nU5Cdx6ryaz2+Lcut\n6tV30i8nnPxLhnG5+9bJpxKfTj3G/Nm+i05DknN1dbUgPhfSUOLb9lsM5aWce+Pq8Z34ywsn/5KA\npAeQrNHX0B7z963E17x+El8XzqSDj2E5XUhDl89KET9XpONe/esLJ/+CUcXLr6W6qu5rGI+LbB4c\nHBTEt804SHwukW3XzmOpLrdcs81c5p7b+NcLTv4lQsrDb2P61smnUt+W5mqFnrXzVaJT6qvkJ/Ht\nKjpO/JsDJ/+SIBXeK/Puk/wkPMnPbruaxJMivi6TbWP6m5ubIwk8ZYtl6tJZhBP/esDJvwSwqbzq\n6FOVP+XdVycfPfu26aYSn2RXZ58SX9fO05VybeZeivhO+uuFlXEXhBBeCiG8HUL4tpx7IoTwagjh\ne8P97dkO8+bDSn5tzUWpr04+9e7n1H0t1mE8n+E6tfW1YEdt/NSCmbkOPE7864ex5AfwBwA+bM59\nCsCXY4zvA/Dl4WvHhLDk1977mrhDdZ+kV6mv3v1Go1FIfV0JN6XyswNPapnscQk8TvzribHkjzF+\nBcC75vRzAF4eHr8M4BemPK7aIpfYQxVfNxKfyTzW1tcSXd1IfJI+tWhmqkgnFcZz4l9fVJH8KTwV\nY3xzePxDAE9NaTy1hY3z65LamthD55526GVoj624AIxIfUp7Vfe50bNvO+3Szq+yqIbjeuKq5C8Q\nz5+2mHs/hHAvhHA/hHD/wYMHk/7cjUSudp92v3ryNZbPPaW+tfVXV1eLMl2q/pT8mthji3RsSM9V\n/JuJq5L/rRDC0wAw3L+duzDG+GKM8W6M8e6dO3eu+HP1wbh8fu3ZR3U/1XK70Wig2WwWkp+TgDbr\n2NzcLOx7puyWOfjcyXezcFXyvwLg+eHx8wC+OJ3h1Au5ll22Qy8JPxgMCrKz6656+K3KT9Jbqa9J\nPrxmnJ3v6v7NQ5VQ3+cB/C8AfzeE8HoI4eMAXgDwsyGE7wH4R8PXjivApvcCSDbqZLyfx9QILPFV\n5adEp/RXyc+++irxc4k87ui7mRib5BNj/FjmrZ+Z8lhqi1wDD7v2Homvqr623QbOpb4lvrX1lfip\n9lu5tF0n/M3CxA4/x9VgG3jwWCW+5vYz4cduKvVZrmvJb9N6u91uqZ0/jvg+CdwMeHrvnGHJzn1Z\nHT+JruW9lPiq7mutvqr7mtxDqZ+z88ep/E78mwOX/HNElZ78GuLTTr3c9D0N7enaeiS92vpazGMb\ncmg8v0zNd+LfLLjkXwDKJL6uwWdtfdUA+LlUk45cXN924rFOvjJ134l/8+DknxPKmnTmuvaQ+CQ/\nNQFKfUp8Sn0lPFV75utr/z2q+7YVl+fu1wtO/gUg15pbpbsm9yj5rYMPOPfwq41vJ4HUclplxHfU\nA07+OSCl5lvnnlX32a8vJf1tTF8z+azUzzn5UjF9b8BZLzj5F4Dcwpuq7jNnX7P4OEFo/31KfS3Z\nTZXvpkJ7TAP2DL56wsk/Z5Sl8TKBh3n7LNyx4T7gscqvoT2r8lvvvlX3dTHNVDjPJ4KbDSf/nKAx\n+dyCHCr5mbuvKn+qWQdVfkr3VA4/w38M61FjKMvdd+LffHicf84ok/pU8bVsVyW/Ld7Rmn2N72vj\nDpvC6zX6DsIl/xxhpX9qyW027tASXpX8DPEBKFbYJfnp1FOHnzbmqBLWA1zq1wVO/hkjVbVnVf5c\nxx6r9lvJT3ufEwDVfk3pVTuf5L8pxE/d2+s0/kXDyT8npMJ9qfCerrij1Xu094HHzTo0bJdy+Gne\nfq5iT7EsxEmRepLPLsv/WjY4+eeIsuQeG+Kjra+efkp+OvsY4+dm8/p5LreENrB4z/44old5Pzd2\nnte8CMdjOPnnAPsAp/r0MalH4/upnH6ChKbdr8Rvt9sjiTzjiL8I5Myh3Ptl11fRYEIIPgkYOPnn\nCH2AUxV8dPjpZot5zs7OCtuddrxOANqE06r8OY/+PMlQRupU/UNqXwY7uaX8GT4JnMPJP2ekqvhU\n7dd+falKPuDxwpskN9V/Jb/G9FOluot48KsSXTe9vmwSsP+tLGtRJ4E6TwBO/jkh9SBrbr+G+2y3\nHq3kA1DY/HT8qe0/ri3XojCuiYklvKZAp96zsGS3/1vXFVTS13kCcPLPGaksP12XT7v38LySQCUc\nyc/NVuqVra23iP+s/7tss81NGBmxkwGhBLeRDW68jvfCJwAn/1yRS++1tr8e24IeVeMt+akF5Jx8\n854Aqkh7JXSqylH/u26W/LwX7G3AybDRaBTXrays4OzszCeAIZz8CwIfXpvso2TXzUo7q9KWSb0c\n8Wf1sOeiGzkpb/sW2nth9zpp6D2g6TMYDNBsNnF2doZms4kYYzEJ+ATwGE7+OSOn3uYknS3jTUk8\nlXpVa/Nn8ZCPc+jlJL1qO9b00SQnbWii5Of/VYfn2trayISp92FlZWXkfN1ITzj5F4Sc118nALX3\nSX4i5eCqksU3q/9ij8ucdylzJ1XZmFqpiM7PVHWjLkuW6m5skXIC1mkicPLPECk7177Wh79M7Sf5\nU5NA2dJas54EcuE465yzWg4jHLoikZKce65CzEInLXBS8lPac+Vh2/Eodw90AqgbnPwzRs7+tZ7s\nnLNPJR0fVMKq8fMge+6/jfPY52x6uwoRic6y5n6/X/Q24GrEOfKvr6+PlECnyN9qtS78D72vdZL+\nTv45IaUCp9RetXs15s9JYnV1dUT6z1PKp/4Pj3MOPFu5mGpSqlu/3y8I3+/3R1KeSWwN+yn5WQnJ\n+5W6HzYZaJxpcJPh5J8RqoS5bEWftXmtlGw0Ghc0iTLMajKoQvyULc//RBLThj88PCxKmXVL9TU4\nPj4eIT99HWtrayMLl/L/V4l6ABedgHWAk38GSBHUkkTteSW9lYq2qMfGuIHHD6tVX1OY5MEuC+Gl\nPPeU5lalZ98C3UhynQjsZ9Tjz/vB8CavsWnQNt8h18yE/6NOYT8n/wyRc/RZ6ahNO6x3W9VYfkdq\nArD+AGA6ob3cRJb7P5zMVFVXSb6/v1+o80pwSnclu94D9fxb8tPZl5L6NgSqvQs1WcqGJm868YEK\n5A8hvATgHwN4O8b4k8NznwHwqwAeDC/7dIzxS7Ma5HVCTi1PESa1LJcNa6nUDyGMlPWmMK2HNiXl\n9TinyXD8JDdt+L29PfR6PfR6vWIiUMKnKhp1ErEtzDkeDfPpfdKkJ9u4VGsiGo1G0RqtDtJeUUXy\n/wGAfwvgc+b878QYf3PqI7ohyMW7aevb/n1qG+sDT7UfwIh6mpL+0xx36n/of7C+C0v8fr+P/f19\n7O/v49GjR3j06BF6vR729/eTDUp1s4RXE0ilPvBY8jMCwPukxNdmJ5wImAnI6/T/1GUCGEv+GONX\nQgjPzn4oNw8paanhPesBtwkuKvlDCMm89lmOV8etxznzRSX+/v4+9vb28PDhQzx8+BA7OzvY29sr\nyE87XzsYKdE1s089/DZ+32g0ivsEYETip7ocsechU4D5var61wWT2PyfCCH8EwD3AXwyxvhwSmO6\ntqiq8itx9AG3JoA6BZmTPgupn3PkpcYMPK5H0HJkEvjg4AC9Xq8g/o9+9CPs7OwkJT8nAJ3s7AIl\ntOOV+Jb8q6urI2E/295Mm5uysWmqKWrdcFXy/x6Afw0gDve/BeCfpi4MIdwDcA8AnnnmmSv+3PVF\nSm1OVa/ZWL/NZdfPznq8KQmfCufpmEn8fr+PXq9XEJ8q/+7uLvb29gpzgLF8VfttRiMdnWXVfJr3\nwAYnJHyr1Sq0Ed0r8VM9A+qi+l+J/DHGt3gcQvh9AP+l5NoXAbwIAHfv3q3nFDtEzlGWio3b9+zn\n+XrW47Pks6S3Lcd7vR4ePXp0gfgkP1V/pu2S9LZ0maZRipgEVfUYz+P9OhGpSWHDjbZAKCf9b/ok\ncCXyhxCejjG+OXz5iwC+Pb0hXX+MU6O5T2XDWQJYyZT7jcuMLRXLztnzqTCedU6qnb+zs1PY+I8e\nPcLe3l5BfL6mym87E6tqbwua7P+nD4ShO82KtNGTVJMULQ6qK6qE+j4P4EMAngwhvA7gXwL4UAjh\n/ThX+18D8GszHOONQ8pbnip8USLYVNSr/KZ9ze+0YyrL1NPkHarRlPiU8Lu7u9jZ2SlIz/co9TVj\nz5Yw5yY8O35bomvvm/oNbKWkzZuY5L5eZ1Tx9n8scfqzMxjLjUOKcNwryfScxSxt/Fw0wmYgWi+8\nZuNpDJ9qvRK+1+thZ2cHOzs7BfHVzk8581JaUtl/yJlS1qRKaRZ1JT7gGX5LAX34Uh79SaV9bhJS\nyW81D5uim0rJ1cSd/f394lhfU+Jb777a3WXEL/v/arLYiVTJbTUL5gnUlfSEk38JYFVYTT3l+1dF\nSrrb95QsaturpCd5qeJboutGjz+1AYb3bOKSmjuXIX3Z+6mJNHddnaU+4ORfCGyRSeq8HtPm5zVl\nGCftc85Im3dgG2owjEdVnqTmRoefnRw0m8/G8HPEvwwhc9dac8nJfhFO/hlC1Wq+5l63XKdd1QL0\n81WRIpV1HFo7X2sLaNNTkttwHaW8Tg5WA7BJPDaaMWkUI3dPUoVOV/2Nmwon/xyQqiO3teZlHXgp\n+VNVeiq5U0g5GVO2siW+FuXQe1+F+HrOZu7ZvoRl3vxpY97NTq4DnPwzgJX4et5OBEp0rUCzC05U\nacppIwcasst1sCHxbWMNkpnEZ+iu1+sV71GlV9JrtZ7NzU8RfxLS631I1ekvsrfhdYCTf86w9r6V\n+Fx1p9ls4vj4eKTfvCIXNtSwlpLbah58z2bqUWprNV5K6quNz8+kOu7kVh6apv2dI7Vta17WzKOO\ncPLPGKmHTB9CXWlXi1J0rT3a6mr/A+WxeTrW+B3AY+1BJwVNiVWJzww9Sn2Sn+9TA9BOPClJn7Px\nJ5X4ZYTXij67otEyLVy6aDj5p4icuq8os/N1ArDk52eBdHFQrgkoP6N+A2vn29z83d3dEeJrdh5j\n+yrtU6W3tj5hWtLeEpbpvanJ1G6cVFNmVR3h5J8hdDKw0t92k0k9rFquyu8AMEIqJToLWtrtNo6O\njkau1wddtQTtia/E11RdEl5r8jVTLyXlU8k7kzr3ctESew+5ao8t62Vdvy5oWqb633RtwMk/I5D4\nKS+92p2USKmHd3V1teg2o978cWp7q9UaITo1C45D03YZz7ehPB5rii6PGbfXHvqpKrlZE1/VeN47\n1u632+2igQeP2+021tbWstK/bj4AJ/8ckYrvq52fcvrZ9lSaiaeOOmbhkfinp6fodDo4OjoqJCOA\n4rMkLh133DQ3n1JeVX+N3VtHXs6unzbx1YmnjTtI9E6ng/X19WLprk6nU5xbX18vrud9qRPhFU7+\nKaNKmE8ljlXxrY1q7X4lvubc9/v9QprFGAszgA+6mgC2AUcqQYd2var+dPCl1swrI/s0wnmW+OrU\no6ZEgne73WIS0HPdbrfQDPS+103iE07+GcKG13hsH2TbdoqqPx/QwWAwQjDbHvvw8HBkLXra8vod\nBMmv6bu6UAbj9azW293dHWm3bXsLlqn103DuqY/Eaks6SZLoJD7J3u12sbm5iY2NDWxsbBSqv2pa\n817YdFng5J8BUtI/5eyzar7tNKuqqarU6uBT4tMsoDqvmgPw2FdgF8akBsC9LdTRohzbXmwWWXop\n+15VfZ0g19bWRqT7xsZGMRFsbGxgc3MTW1tb2NraKtR+dQaq/6VucPLPATkvtbX5bWtpnRROTk5G\nHHbHx8dYXV1Fv9+/QHyq+yrVgMcmg3UU0nxQya9NNqklVMnNn9Z94l4do2omkfgkPaU7Sa/E39zc\nLCYI9vaz96eOST9O/hnBSv9Ugg+lWSo0ZZtQqvSn6s5wnnay4Xnr4QdGQ3za9ko78mijDqboqo2f\ny82fxv3iPufYo5bEe0U1nySn5N/c3ByR+JwUqpC/TnDyzxipSSBl73MCoENKz/HBV+LpQh4ACmLy\n4VZ1HxhNDLKktktk2XbimqI7q/Rce29S0l4nRZKZRFfib2xsFMSn1Ge4TzP/Ur0T7JhuMpz8c0Aq\nBdV6rUla3XQSoHcfeKy+k3x2xRzNDgQwEh7UDj06AaSaXGqWnm1/Nc17w7116tG+Vxu/3W6j3W5j\nY2OjkPqdTmdE0m9vb2N7extbW1sjYT/eY70/dc7zd/LPEGWqvw1XMSbNh7vdbuPw8PCC6q9E5DJT\nmu3H6zSPH3g8QdhiGyvZU1l6syrBrWrb2xg+yZ5z7N2+fRu3bt1Ct9tFp9MZUfVtck9diQ84+ecO\nK/2pzirpqfrzgWfePW14knAwGBT2PtV5TVsldIKwBUCah69mRUrSz5L4tsZBnXq62g6defY1yU/i\n085PSfzUSr2psd10OPnnhJTqb2P8DEWtr6/j8PCwID5Vf31QbckuCaRRAcKSOdfZNpWey8/r/ir/\nPfW6LHFHbXuV8N1udyRph+Snum+Jr87UMju/LoRXOPnngJT6r+TXDLVOp1OE2Six1tfXsb+/j2az\nicPDw+IMxjOJAAAM6klEQVT71O6nKWHJr2W/urc1/9MmfYpYVeL3urYe7XUS3E4C6tnf3t4uHH+c\nQHMJPWXqfp0mASf/HGEfOE3rXVtbw/HxMTqdDvr9PtbX14siHRJCc/SB0a67IYQLTTuUvDb33k4G\n01Lvc0TXY9tYw0Y9SF7a9lTzNY6fCufpQpw0GTTykYrn15X4gJN/biAZyx56lf79fr/wAXASsF58\nK/1zSDnrZlV5l0toshKX/8OaPnTqUdrTaadqPsluPfqdTmeE9CmJn4vr1434gJN/5lAJrA+cLeyh\ndKf0p9qqNqu1+60UT4Hntb+ffnaadr3dtNGGEj7l3KNzk2E8VfPVtrdqPiU975cmAVnS2w4+OvY6\nwsm/AKg0VM824+5Ue2n7arIP89Fzdr2eU5SRfNrEVzve1jFoAxNmN6qNbzfr2CPpNzc3C2lv75P+\nVkrr4Jh1X0c4+eeEMnV4dXUVp6enhdQiEWyYint9mFWy26y73ASQej2pfZ/y3JeVKut/peS2Nfgk\nvar7Kaeemk0px54TPw0n/5xhiRJjHCG/xvfVW51rQKFx/3HkLzt/WSKkiK92vK1UVMeljd9rXoOt\nv2cWnxbu2HwI26wzRXon/kU4+RcAJb6S5fT0dCS5hVJNiWRV2pQNO06Kj3vwc++nbGVVq7UAR/Po\nLdFtIhM9/JrBp6o+nX5qDtliqDKnnhM/jbHkDyG8F8DnADwFIAJ4Mcb4uyGEJwD8JwDPAngNwEdj\njA9nN9TrC/X0K9Rrn0py0Tx/OwmkvNVlpC9zcpW9p/3t7PtW6qey8yilldzqkSeZNbxnY/ma/Zi6\nH5xAU9Levfp5VJH8JwA+GWP8eghhE8DXQgivAvgVAF+OMb4QQvgUgE8B+I3ZDfXmIBX3VuefDf/Z\nVl+qXqvzb5zEttEG+569hmOz5/W1qvs6drXfrWNOJb9mNVp1XxN1bH5+Ttrb++HEz2Ms+WOMbwJ4\nc3i8F0L4LoD3AHgOwIeGl70M4H/CyZ+FSn/uU+q/DX+lFp9IqbYrKyvFuvMpQuckYsoZllOdU5OB\nOi1tkw1KetUASOacg4999vTalOaTI31KzbfHjnNcyuYPITwL4KcA/DmAp4YTAwD8EOdmgaMCrBmQ\n8pSrGaCkH5etZlV2JUZKNc4l3+h4Up+1n9FcBZXuas9bSW+bbKrzz9bfWxV/XMaeE388KpM/hLAB\n4I8B/HqMcVdvaIwxhhCSBmcI4R6AewDwzDPPTDbaaw61y+3DmUp5TSWp5JpOqlTW71SyqMRMkdxm\n3dmYvE4EOqHY3no0WUj4lLQn6Sn5U41MlPhl4bsc6VOvHY9RifwhhCbOif+HMcY/GZ5+K4TwdIzx\nzRDC0wDeTn02xvgigBcB4O7du7VfGN1OAFYDSKmzZWo4r+GqPPyeEC7WxltCq/9AVWoSWI9t4o6d\nsNRcSYX0SHj1A6QamNhWZuPi9mUS3olfjire/gDgswC+G2P8bXnrFQDPA3hhuP/iTEZ4A2EngJQE\nUwmdstHLQlo23q6dcFKNQlOtw1MTQS5d1popKRPAeuzVoamfqTrh6L1L3V/HeFSR/D8N4JcBfCuE\n8I3huU/jnPT/OYTwcQB/BeCjsxnizYROAPZ8ypmXe60E5OdzDTFS/QGV2HaS0JBjysNuJ4NUpIK/\nr9+r2YqqkZQ5NnMTnd43x+VQxdv/ZwByd/Znpjuc+qLsgc49/NYpp1JYG4RonF371tt0W9s1mBOF\n9biX+SNS5oWV7Kkc/1z1ncftZwfP8FsClEmx1LFKXUp8+g5INlsXb1tXp6S7Et2m0FJdt2G2VOTA\nOg1TUQw9b82YKtEMJ/3kcPJfEyjxVbVXRx9Vb+15x9h5KkvOOto08YZaQk7qq7ahv59yBNrJIpen\nUJXwTvzpwMl/DWDVf1WbtZOPdrnVJhja4UZj6VbF15BcSkPQBJuc1z01AZSR2jrvUuf0HjimByf/\nNYFKSM0ApNpPdV8lvqbM8ry2B7fOQKv6qzmgdryV3ByfjlOPq1xXds7eB8d04ORfYljJqck6a2tr\nAHChD6CV9qr6ayadJtaoVM+FA6sQX48vuy87Tr12TA4n/5LCSkNV99n1p9FoFP0Ams3miGqvHXC0\nWIYTQi7Wn2q+YWP844ifOx7npc8R3Ik/Gzj5F4wQ0qv6AKN9/jSER6nPfv2U2Kl6+G63WzS8ZNGM\nbQtmvfC5EJx18FVVzS8rxZ3s84GTf4GwxNfzNntOQ3IkPasBOSFon3u2u7KLVWpbsFR5cC6Gb00Q\njlPHnPuPlznvmB+c/EsE6yDTmD0l+2AwAAA0m00A544+zZ3XxSxIfJtLb7sClcXsx3npdezj/ptj\nueDkXxKk1H2Sn975TqeDs7MzNBqNYoEOOvoY3tMlqtkFR9uAp2rix4XicqR3wl9vOPmXCNa5p5l6\nGxsbBeFbrRbOzs5GYvt20UpbI5/rZz8utl4l/Jb6H47lh5N/CZBz8pHYGxsbODk5KTz7g8EAp6en\nIw5Au5BlWYfbMuJX2ZeN33F94ORfElhbXz34JH6j0She8zO2bZZtf5XrcFuWgFN2XHbOcb3g5F8S\nKBHpwdeVdKkNdLvd4ry2z9LcfCW8XcFGPff6u3YsuTE6bg6c/EsEtfdjjGg2m0UokJrAyclJ0ahT\nq+c0/16Pyzz6VWx4J/zNhZN/CZDL5mu1WsVrkp9SH7hY4Wfr6TV+b+P0l/XcO24enPwLhib6kKC0\n73mOpFYzgO/Z1N9xyTlOfAfh5F8SWI+/nRBoCuh6fKoxjCN6zsZ34tcXTv4lAKU/iZgif2ohTr7P\nfS5mX8Wj76gfnPxLhpwGoMTP9f5PxeUvE75z1AtO/iWBtf3tuXEr79rP2XO51476wsm/RCAx7UIe\nqRV+x31H1fOO+sLJv4TQSUBfX+U7HI4cnPxLDCewY5ZYGX+Jw+G4iXDyOxw1hZPf4agpnPwOR03h\n5Hc4agonv8NRU4wlfwjhvSGE/xFC+IsQwndCCP98eP4zIYQ3QgjfGG4fmf1wHQ7HtFAlzn8C4JMx\nxq+HEDYBfC2E8Orwvd+JMf7m7IbncDhmhbHkjzG+CeDN4fFeCOG7AN4z64E5HI7Z4lI2fwjhWQA/\nBeDPh6c+EUL4ZgjhpRDC7cxn7oUQ7ocQ7j948GCiwTocjumhMvlDCBsA/hjAr8cYdwH8HoC/A+D9\nONcMfiv1uRjjizHGuzHGu3fu3JnCkB0OxzRQifwhhCbOif+HMcY/AYAY41sxxtMY4xmA3wfwgdkN\n0+FwTBtVvP0BwGcBfDfG+Nty/mm57BcBfHv6w3M4HLNCFW//TwP4ZQDfCiF8Y3ju0wA+FkJ4P4AI\n4DUAvzaTETocjpmgirf/zwCkaku/NP3hOByOecEz/ByOmsLJ73DUFE5+h6OmcPI7HDWFk9/hqCmc\n/A5HTeHkdzhqCie/w1FTOPkdjprCye9w1BROfoejpnDyOxw1hZPf4agpnPwOR00RuAz0XH4shAcA\n/kpOPQngnbkN4HJY1rEt67gAH9tVMc2x/a0YY6V+eXMl/4UfD+F+jPHuwgZQgmUd27KOC/CxXRWL\nGpur/Q5HTeHkdzhqikWT/8UF/34ZlnVsyzouwMd2VSxkbAu1+R0Ox+KwaMnvcDgWhIWQP4Tw4RDC\n/wkhfD+E8KlFjCGHEMJrIYRvDVcevr/gsbwUQng7hPBtOfdECOHVEML3hvvkMmkLGttSrNxcsrL0\nQu/dsq14PXe1P4TQAPB/AfwsgNcBfBXAx2KMfzHXgWQQQngNwN0Y48JjwiGEfwCgB+BzMcafHJ77\nNwDejTG+MJw4b8cYf2NJxvYZAL1Fr9w8XFDmaV1ZGsAvAPgVLPDelYzro1jAfVuE5P8AgO/HGH8Q\nYzwG8EcAnlvAOJYeMcavAHjXnH4OwMvD45dx/vDMHZmxLQVijG/GGL8+PN4DwJWlF3rvSsa1ECyC\n/O8B8Nfy+nUs15LfEcCfhhC+FkK4t+jBJPDUcNl0APghgKcWOZgExq7cPE+YlaWX5t5dZcXracMd\nfhfxwRjj3wfw8wD+2VC9XUrEc5ttmcI1lVZunhcSK0sXWOS9u+qK19PGIsj/BoD3yusfG55bCsQY\n3xju3wbwBSzf6sNvcZHU4f7tBY+nwDKt3JxaWRpLcO+WacXrRZD/qwDeF0L48RBCC8AvAXhlAeO4\ngBBCd+iIQQihC+DnsHyrD78C4Pnh8fMAvrjAsYxgWVZuzq0sjQXfu6Vb8TrGOPcNwEdw7vH/fwD+\nxSLGkBnX3wbwv4fbdxY9NgCfx7kaOMC5b+TjAP4GgC8D+B6A/w7giSUa238A8C0A38Q50Z5e0Ng+\niHOV/psAvjHcPrLoe1cyroXcN8/wczhqCnf4ORw1hZPf4agpnPwOR03h5Hc4agonv8NRUzj5HY6a\nwsnvcNQUTn6Ho6b4/8hEU3szqbL7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116defd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = data.train.images[3]\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys', interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "img_size = 28\n",
    "img_channel = 1\n",
    "\n",
    "# Network\n",
    "conv_filter = 5\n",
    "deconv_filter = 3\n",
    "strides = [1, 2, 2, 1]\n",
    "conv_1 = 16\n",
    "conv_2 = 32\n",
    "fc_1_size = 1024\n",
    "fc_2_size = 1\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weight initializer\n",
    "def weight(shape, layer_name):\n",
    "    return tf.get_variable(layer_name, shape, initializer=tf.truncated_normal_initializer(stddev=0.2))\n",
    "\n",
    "# Bias initializer\n",
    "def bias(shape, layer_name):\n",
    "    return tf.get_variable(layer_name, [shape], initializer=tf.constant_initializer(0))\n",
    "\n",
    "# Convolutional block\n",
    "def conv_block(layer, W, b):\n",
    "    layer = tf.nn.conv2d(layer, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    layer = layer + b  # add bias\n",
    "    layer = tf.nn.relu(layer)\n",
    "    layer = tf.nn.max_pool(layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return layer\n",
    "\n",
    "# Deconvolutional block\n",
    "def deconv_block(layer, W, b, activation_fn=tf.nn.relu, batch_norm=None):\n",
    "    layer = tf.nn.conv2d(layer, W, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    layer = layer + b\n",
    "    if batch_norm:\n",
    "        layer = tf.contrib.layers.batch_norm(layer, epsilon=1e-5, scope=batch_norm)\n",
    "    layer = activation_fn(layer)\n",
    "    return layer\n",
    "\n",
    "# Fully connected layer\n",
    "def fully_connected(layer, W, b, use_relu=True):\n",
    "    layer = tf.matmul(layer, W) + b\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "# Flatten layer\n",
    "def flatten(layer):\n",
    "    shape = layer.get_shape()\n",
    "    features = np.array(shape[1:4], dtype=np.int32).prod()\n",
    "    flattened = tf.reshape(layer, [-1, features])\n",
    "    return flattened, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator `(Deep Convolutional neural net)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(image, reuse=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse) as scope:\n",
    "        # 1st convolutional block\n",
    "        d_conv_W1 = weight(shape=[conv_filter, conv_filter, img_channel, conv_1], layer_name='d_conv_W1')\n",
    "        d_conv_b1 = bias(shape=conv_1, layer_name='d_conv_b1')\n",
    "        d_conv_1 = conv_block(image, d_conv_W1, d_conv_b1)\n",
    "        # 2nd convolutional block\n",
    "        d_conv_W2 = weight(shape=[conv_filter, conv_filter, conv_1, conv_2], layer_name='d_conv_W2')\n",
    "        d_conv_b2 = bias(shape=conv_2, layer_name='d_conv_b2')\n",
    "        d_conv_2 = conv_block(d_conv_1, d_conv_W2, d_conv_b2)\n",
    "        # Flatten layer\n",
    "        flattened, features = flatten(d_conv_2)\n",
    "        # 1st Fully connected layer\n",
    "        d_fc_W1 = weight(shape=[features, fc_1_size], layer_name='d_fc_W1')\n",
    "        d_fc_b1 = bias(shape=fc_1_size, layer_name='d_fc_b1')\n",
    "        fc_1 = fully_connected(flattened, d_fc_W1, d_fc_b1, use_relu=True)\n",
    "        # 2nd Fully connected layer\n",
    "        d_fc_W2 = weight(shape=[fc_1_size, fc_2_size], layer_name='d_fc_W2')\n",
    "        d_fc_b2 = bias(shape=fc_2_size, layer_name='d_fc_b2')\n",
    "        fc_2 = fully_connected(fc_1, d_fc_W2, d_fc_b2, use_relu=False)\n",
    "        return fc_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator `(Deep Deconvolutional neural net)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim, scale=56):\n",
    "    up_scale = scale * scale\n",
    "    # 1st Deconvolutional block\n",
    "    g_deconv_W1 = weight(shape=[z_dim, up_scale], layer_name='g_deconv_W1')\n",
    "    g_deconv_b1 = bias(shape=up_scale, layer_name='g_deconv_b1')\n",
    "    g_deconv_1 = tf.matmul(z, g_deconv_W1) + g_deconv_b1\n",
    "    g_deconv_1 = tf.reshape(g_deconv_1, [-1, scale, scale, img_channel])\n",
    "    g_deconv_1 = tf.contrib.layers.batch_norm(g_deconv_1, epsilon=1e-5, scope='bn_G1')\n",
    "    g_deconv_1 = tf.nn.relu(g_deconv_1)\n",
    "    # 2nd Deconvolutional block\n",
    "    g_deconv_W2 = weight(shape=[deconv_filter, deconv_filter, img_channel, z_dim//2], layer_name='g_deconv_W2')\n",
    "    g_deconv_b2 = bias(shape=z_dim//2, layer_name='g_deconv_b2')\n",
    "    g_deconv_2 = deconv_block(g_deconv_1, g_deconv_W2, g_deconv_b2, batch_norm='bn_G2')\n",
    "    g_deconv_2 = tf.image.resize_images(g_deconv_2, [scale, scale])\n",
    "    # 3rd Deconvolutional block\n",
    "    g_deconv_W3 = weight(shape=[deconv_filter, deconv_filter, z_dim//2, z_dim//4], layer_name='g_deconv_W3')\n",
    "    g_deconv_b3 = bias(shape=z_dim//4, layer_name='g_deconv_b3')\n",
    "    g_deconv_3 = deconv_block(g_deconv_2, g_deconv_W3, g_deconv_b3, batch_norm='bn_G3')\n",
    "    g_deconv_3 = tf.image.resize_images(g_deconv_3, [scale, scale])\n",
    "    # Final Deconvolutional block\n",
    "    g_deconv_W4 = weight(shape=[1, 1, z_dim//4, 1], layer_name='g_deconv_W4')\n",
    "    g_deconv_b4 = bias(shape=1, layer_name='g_deconv_b4')\n",
    "    g_deconv_4 = deconv_block(g_deconv_3, g_deconv_W4, g_deconv_b4, activation_fn=tf.nn.sigmoid)\n",
    "    \n",
    "    return g_deconv_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable g_deconv_W1 already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-5-331a14620148>\", line 3, in weight\n    return tf.get_variable(layer_name, shape, initializer=tf.truncated_normal_initializer(stddev=0.2))\n  File \"<ipython-input-7-f9e886fac3a5>\", line 4, in generator\n    g_deconv_W1 = weight(shape=[z_dim, up_scale], layer_name='g_deconv_W1')\n  File \"<ipython-input-15-76ae62a3d0f0>\", line 7, in <module>\n    Gz = generator(z_placeholder, batch_size, z_dim)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-50ac1fdbf35d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-422e267a0aa3>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(z, batch_size, z_dim, scale)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mup_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 1st Deconvolutional block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mg_deconv_W1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_scale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g_deconv_W1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mg_deconv_b1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mup_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g_deconv_b1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mg_deconv_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_deconv_W1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mg_deconv_b1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-331a14620148>\u001b[0m in \u001b[0;36mweight\u001b[0;34m(shape, layer_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Weight initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Bias initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    662\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 664\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable g_deconv_W1 already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-5-331a14620148>\", line 3, in weight\n    return tf.get_variable(layer_name, shape, initializer=tf.truncated_normal_initializer(stddev=0.2))\n  File \"<ipython-input-7-f9e886fac3a5>\", line 4, in generator\n    g_deconv_W1 = weight(shape=[z_dim, up_scale], layer_name='g_deconv_W1')\n  File \"<ipython-input-15-76ae62a3d0f0>\", line 7, in <module>\n    Gz = generator(z_placeholder, batch_size, z_dim)\n"
     ]
    }
   ],
   "source": [
    "gen_img = generator(z_placeholder, 1, z_dim)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'Sigmoid:0' shape=(?, 28, 28, 1) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    269\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 270\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    271\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2707\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2786\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c3efd093af2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1109\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \"\"\"\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 277\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    278\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'Sigmoid:0' shape=(?, 28, 28, 1) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    test_img = sess.run(gen_img, feed_dict={z_placeholder: z_batch})\n",
    "    print(test_img.shape)\n",
    "    plt.title('Test image')\n",
    "    plt.imshow(test_img.reshape([img_size, img_size]), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dim], name='z_placeholder')\n",
    "x_placeholder = tf.placeholder(tf.float32, [None, img_size, img_size, img_channel], name='x_placeholder')\n",
    "\n",
    "# Genenrated img\n",
    "Gz = generator(z_placeholder, batch_size, z_dim)\n",
    "# Prob. for real img\n",
    "Dx = discriminator(x_placeholder)\n",
    "# Prob. for generated img\n",
    "Dg = discriminator(Gz, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator loss\n",
    "d_loss_real = tf.nn.softmax_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx))\n",
    "d_loss_fake = tf.nn.softmax_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg))\n",
    "# Generator loss\n",
    "g_loss = tf.nn.softmax_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "d_loss_real = tf.reduce_mean(d_loss_real)\n",
    "d_loss_fake = tf.reduce_mean(d_loss_fake)\n",
    "# Generator\n",
    "g_loss = tf.reduce_mean(g_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Trainable Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d_conv_W1:0', 'd_conv_b1:0', 'd_conv_W2:0', 'd_conv_b2:0', 'd_fc_W1:0', 'd_fc_b1:0', 'd_fc_W2:0', 'd_fc_b2:0']\n",
      "['g_deconv_W1:0', 'g_deconv_b1:0', 'g_bn_1/beta:0', 'g_deconv_W2:0', 'g_deconv_b2:0', 'g_bn_2/beta:0', 'g_deconv_W3:0', 'g_deconv_b3:0', 'g_bn_3/beta:0', 'g_deconv_W4:0', 'g_deconv_b4:0']\n"
     ]
    }
   ],
   "source": [
    "t_vars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "\n",
    "print([var.name for var in d_vars])\n",
    "print([var.name for var in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
