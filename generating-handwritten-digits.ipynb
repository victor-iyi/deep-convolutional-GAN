{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119fcaef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUIQfCIrwA0ERfiAowg8E9f+pv2+r8RPaCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116da1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = data.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n",
    "        # First convolutional and pool layers\n",
    "        # This finds 32 different 5 x 5 pixel features\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # Second convolutional and pool layers\n",
    "        # This finds 64 different 5 x 5 pixel features\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.nn.relu(d2)\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.nn.relu(d3)\n",
    "\n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "        # d4 contains unscaled values\n",
    "        return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1205a1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output,\n",
    "                                feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28, 28])\n",
    "    plt.imshow(generated_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "# z_placeholder is for feeding input noise to the generator\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_placeholder') \n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "# Gz holds the generated images\n",
    "\n",
    "Dx = discriminator(x_placeholder) \n",
    "# Dx will hold discriminator prediction probabilities\n",
    "# for the real MNIST images\n",
    "\n",
    "Dg = discriminator(Gz, reuse_variables=True)\n",
    "# Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d_w1:0', 'd_b1:0', 'd_w2:0', 'd_b2:0', 'd_w3:0', 'd_b3:0', 'd_w4:0', 'd_b4:0']\n",
      "['g_w1:0', 'g_b1:0', 'g_w2:0', 'g_b2:0', 'g_w3:0', 'g_b3:0', 'g_w4:0', 'g_b4:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the discriminator\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From this point forward, reuse variables\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLossReal: 0.692837 dLossFake: 0.716971\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Pre-train discriminator\n",
    "for i in range(300):\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "    real_image_batch = data.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "    if(i % 100 == 0):\n",
    "        print(\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake)\n",
    "\n",
    "# Train generator and discriminator together\n",
    "for i in range(1000):\n",
    "    real_image_batch = data.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "\n",
    "    # Train discriminator on both real and fake images\n",
    "    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "    # Train generator\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "    _ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        # Update TensorBoard with summary statistics\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "        summary = sess.run(merged, {z_placeholder: z_batch, x_placeholder: real_image_batch})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # Every 100 iterations, show a generated image\n",
    "        print(\"Iteration:\", i, \"at\", datetime.datetime.now())\n",
    "        z_batch = np.random.normal(0, 1, size=[1, z_dimensions])\n",
    "        generated_images = generator(z_placeholder, 1, z_dimensions)\n",
    "        images = sess.run(generated_images, {z_placeholder: z_batch})\n",
    "        plt.imshow(images[0].reshape([28, 28]), cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "        # Show discriminator's estimate\n",
    "        im = images[0].reshape([1, 28, 28, 1])\n",
    "        result = discriminator(x_placeholder)\n",
    "        estimate = sess.run(result, {x_placeholder: im})\n",
    "        print(\"Estimate:\", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
