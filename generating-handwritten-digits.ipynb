{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_image = data.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n",
    "        # First convolutional and pool layers\n",
    "        # This finds 32 different 5 x 5 pixel features\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # Second convolutional and pool layers\n",
    "        # This finds 64 different 5 x 5 pixel features\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.nn.relu(d2)\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.nn.relu(d3)\n",
    "\n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "        # d4 contains unscaled values\n",
    "        return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output,\n",
    "                                feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28, 28])\n",
    "    plt.imshow(generated_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "# z_placeholder is for feeding input noise to the generator\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_placeholder') \n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "# Gz holds the generated images\n",
    "\n",
    "Dx = discriminator(x_placeholder) \n",
    "# Dx will hold discriminator prediction probabilities\n",
    "# for the real MNIST images\n",
    "\n",
    "Dg = discriminator(Gz, reuse_variables=True)\n",
    "# Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the discriminator\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From this point forward, reuse variables\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Pre-train discriminator\n",
    "for i in range(300):\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "    real_image_batch = data.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "    if(i % 100 == 0):\n",
    "        print(\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake)\n",
    "\n",
    "# Train generator and discriminator together\n",
    "for i in range(1000):\n",
    "    real_image_batch = data.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "\n",
    "    # Train discriminator on both real and fake images\n",
    "    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "    # Train generator\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "    _ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        # Update TensorBoard with summary statistics\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "        summary = sess.run(merged, {z_placeholder: z_batch, x_placeholder: real_image_batch})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # Every 100 iterations, show a generated image\n",
    "        print(\"Iteration:\", i, \"at\", datetime.datetime.now())\n",
    "        z_batch = np.random.normal(0, 1, size=[1, z_dimensions])\n",
    "        generated_images = generator(z_placeholder, 1, z_dimensions)\n",
    "        images = sess.run(generated_images, {z_placeholder: z_batch})\n",
    "        plt.imshow(images[0].reshape([28, 28]), cmap='Greys')\n",
    "        plt.show()\n",
    "\n",
    "        # Show discriminator's estimate\n",
    "        im = images[0].reshape([1, 28, 28, 1])\n",
    "        result = discriminator(x_placeholder)\n",
    "        estimate = sess.run(result, {x_placeholder: im})\n",
    "        print(\"Estimate:\", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
